{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96f9ca32-c4c2-4dcf-9768-d001babf9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import src.features.basic as ftr_basic\n",
    "import src.models.training as train_model\n",
    "import src.utils.io as io_utils\n",
    "import src.visualization.plotting as visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e99091-05cd-4104-a81c-17252ab87607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "ROOT = Path(os.getenv(\"ROOT\"))\n",
    "CONFIG_DIR = ROOT / Path(\"src/config/\")\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af759ea8-e47b-4369-af8a-19ead9696db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>contact</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>was_contact</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>job_marital</th>\n",
       "      <th>job_education</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_cat</th>\n",
       "      <th>log_duration</th>\n",
       "      <th>log_balance</th>\n",
       "      <th>multiply_logs</th>\n",
       "      <th>is_overdraft</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>cos_month</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>jb_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>blue-collar_married</td>\n",
       "      <td>blue-collar_primary</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.697093</td>\n",
       "      <td>7.300473</td>\n",
       "      <td>41.591476</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>972.500400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>cellular</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technician_divorced</td>\n",
       "      <td>technician_secondary</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.137727</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>23.760375</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>1073.106634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>primary</td>\n",
       "      <td>telephone</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>blue-collar_single</td>\n",
       "      <td>blue-collar_primary</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.276643</td>\n",
       "      <td>6.318968</td>\n",
       "      <td>39.661910</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>972.500400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>single</td>\n",
       "      <td>primary</td>\n",
       "      <td>cellular</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unemployed_single</td>\n",
       "      <td>unemployed_primary</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.468060</td>\n",
       "      <td>7.635787</td>\n",
       "      <td>41.752942</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>1429.215033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>cellular</td>\n",
       "      <td>success</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>technician_married</td>\n",
       "      <td>technician_secondary</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;5</td>\n",
       "      <td>6.419995</td>\n",
       "      <td>6.763885</td>\n",
       "      <td>43.424107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.988468</td>\n",
       "      <td>0.151428</td>\n",
       "      <td>1073.106634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job   marital  education    contact poutcome  was_contact  \\\n",
       "0   30  blue-collar   married    primary    unknown  unknown            0   \n",
       "1   33   technician  divorced  secondary   cellular  unknown            0   \n",
       "2   28  blue-collar    single    primary  telephone  unknown            0   \n",
       "3   29   unemployed    single    primary   cellular  unknown            0   \n",
       "4   55   technician   married  secondary   cellular  success            1   \n",
       "\n",
       "   credit_score          job_marital         job_education  ... previous_cat  \\\n",
       "0             1  blue-collar_married   blue-collar_primary  ...            0   \n",
       "1             0  technician_divorced  technician_secondary  ...            0   \n",
       "2             1   blue-collar_single   blue-collar_primary  ...            0   \n",
       "3             0    unemployed_single    unemployed_primary  ...            0   \n",
       "4             1   technician_married  technician_secondary  ...           <5   \n",
       "\n",
       "  log_duration log_balance multiply_logs  is_overdraft  sin_month  cos_month  \\\n",
       "0     5.697093    7.300473     41.591476             0   0.866025  -0.500000   \n",
       "1     6.137727    3.871201     23.760375             0  -0.500000  -0.866025   \n",
       "2     6.276643    6.318968     39.661910             0   0.866025  -0.500000   \n",
       "3     5.468060    7.635787     41.752942             0   0.500000   0.866025   \n",
       "4     6.419995    6.763885     43.424107             0   0.500000  -0.866025   \n",
       "\n",
       "    sin_day   cos_day      jb_mean  \n",
       "0  0.299363 -0.954139   972.500400  \n",
       "1  0.937752  0.347305  1073.106634  \n",
       "2  0.651372 -0.758758   972.500400  \n",
       "3  0.394356  0.918958  1429.215033  \n",
       "4  0.988468  0.151428  1073.106634  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cfg = io_utils.load_yaml(CONFIG_DIR / \"data.yaml\")\n",
    "DATA_NEW_FTR = data_cfg[\"new_features_train_data\"]\n",
    "\n",
    "data_train = io_utils.load_df_parquet(ROOT / DATA_NEW_FTR[\"train_new_features_path\"])\n",
    "data_val = io_utils.load_df_parquet(ROOT / DATA_NEW_FTR[\"val_new_features_path\"])\n",
    "\n",
    "target_train = io_utils.load_df_parquet(ROOT / DATA_NEW_FTR[\"train_target_path\"])\n",
    "target_val = io_utils.load_df_parquet(ROOT / DATA_NEW_FTR[\"val_target_path\"])\n",
    "\n",
    "data_ids = io_utils.load_df_parquet(\n",
    "    ROOT / data_cfg[\"origin_train_data_clean\"][\"ids_path\"]\n",
    ")\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ac7353-4aab-4ae4-ae35-591f26413b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_names = ftr_basic.get_features_names(data_train)\n",
    "cat_features, num_features = ftr_names[\"categorical\"], ftr_names[\"numeric\"]\n",
    "\n",
    "data_train = ftr_basic.cat_features_to_category(data_train)\n",
    "data_val = ftr_basic.cat_features_to_category(data_val)\n",
    "\n",
    "data_train, data_val = ftr_basic.align_categorical_levels(\n",
    "    data_train, data_val, cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d53870-5c38-4878-9d25-1c1986614ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8f7ec9-3b00-479d-b332-1959b3261c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'contact',\n",
       " 'poutcome',\n",
       " 'job_marital',\n",
       " 'job_education',\n",
       " 'education_marital',\n",
       " 'campaign_cat',\n",
       " 'pdays_cat',\n",
       " 'previous_cat']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3c8f68d-e637-4f6c-8488-f5a16c35acfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'metric': 'auc',\n",
       " 'n_estimators': 10000,\n",
       " 'class_weight': 'balanced',\n",
       " 'random_state': 42,\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg = io_utils.load_yaml(CONFIG_DIR / \"models.yml\")[\"lgbm_searh\"]\n",
    "\n",
    "PARAMS_PATH = ROOT / model_cfg[\"params_path\"]\n",
    "params = io_utils.load_yaml(PARAMS_PATH)\n",
    "lgbm_base_params = params[\"params\"]\n",
    "rand_search_param = params[\"randomized\"]\n",
    "\n",
    "lgbm_base_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "938a66ff-b239-40fe-935a-8261d357318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = rand_search_param[\"n_iter\"]\n",
    "cv = rand_search_param[\"cv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "946688c7-d804-472e-8efe-0b277600b033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== comb params 1/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "mean auc for params: 0.9670569121654427\n",
      "=============== comb params 2/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946828483981249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946828483981249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8931595360241993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8931595360241993\n",
      "mean auc for params: 0.9660878424959197\n",
      "=============== comb params 3/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8063577904389605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8063577904389605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9274263220256121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9274263220256121\n",
      "mean auc for params: 0.9667422366308869\n",
      "=============== comb params 4/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9049146859727364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049146859727364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=156, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=156\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7462868476202643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7462868476202643\n",
      "mean auc for params: 0.9668728662192542\n",
      "=============== comb params 5/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8427114778677801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8427114778677801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7389764516006414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7389764516006414\n",
      "mean auc for params: 0.9664595119057905\n",
      "=============== comb params 6/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9414293072490405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9414293072490405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9496779404185604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9496779404185604\n",
      "mean auc for params: 0.9659445990301107\n",
      "=============== comb params 7/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994552569776096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994552569776096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9360773132506415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9360773132506415\n",
      "mean auc for params: 0.9666525884167677\n",
      "=============== comb params 8/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8413288618429398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8413288618429398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9005208885371415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005208885371415\n",
      "mean auc for params: 0.966406513450973\n",
      "=============== comb params 9/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8310152167697087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8310152167697087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7092453503703818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092453503703818\n",
      "mean auc for params: 0.9662731437504443\n",
      "=============== comb params 10/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985749544180686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985749544180686\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788078127330005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788078127330005\n",
      "mean auc for params: 0.9664812300447929\n",
      "=============== comb params 11/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7270143582326924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7270143582326924\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7068136219401581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068136219401581\n",
      "mean auc for params: 0.9662376724751566\n",
      "=============== comb params 12/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143063678289447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143063678289447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8338468826722092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8338468826722092\n",
      "mean auc for params: 0.9660708478826332\n",
      "=============== comb params 13/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099121401432249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099121401432249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] feature_fraction is set=0.972574207212282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.972574207212282\n",
      "mean auc for params: 0.9669073175787556\n",
      "=============== comb params 14/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9707807189631525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707807189631525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289172886460498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289172886460498\n",
      "mean auc for params: 0.9664200160650545\n",
      "=============== comb params 15/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.915838886785281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.915838886785281\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] feature_fraction is set=0.927555858950563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.927555858950563\n",
      "mean auc for params: 0.9662867901407136\n",
      "=============== comb params 16/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481972457733556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481972457733556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124842521585677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124842521585677\n",
      "mean auc for params: 0.9661957916670648\n",
      "=============== comb params 17/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040609413604511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040609413604511\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8743183419101185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8743183419101185\n",
      "mean auc for params: 0.9658365866906907\n",
      "=============== comb params 18/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8472120983063562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8472120983063562\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8459974992514481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8459974992514481\n",
      "mean auc for params: 0.9665963759797241\n",
      "=============== comb params 19/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7064836239640991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064836239640991\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] feature_fraction is set=0.831673438091514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.831673438091514\n",
      "mean auc for params: 0.9665645309217544\n",
      "=============== comb params 20/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8978267904075705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8978267904075705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843701351517025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843701351517025\n",
      "mean auc for params: 0.9666305110612718\n",
      "=============== comb params 21/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8112766851587316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8112766851587316\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8664557408174449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8664557408174449\n",
      "mean auc for params: 0.9664658494150146\n",
      "=============== comb params 22/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.980813071014689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.980813071014689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7767895271702808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7767895271702808\n",
      "mean auc for params: 0.9658852076776375\n",
      "=============== comb params 23/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.968033991909359, subsample=1.0 will be ignored. Current value: bagging_fraction=0.968033991909359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9672377472635574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9672377472635574\n",
      "mean auc for params: 0.9662757004451327\n",
      "=============== comb params 24/24 ===============\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 374999, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] Number of positive: 45244, number of negative: 329756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 375000, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7787381547768594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7787381547768594\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9240368834047078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9240368834047078\n",
      "mean auc for params: 0.9663889285893115\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Info] Number of positive: 67866, number of negative: 494633\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 562499, number of used features: 23\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282532043662948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282532043662948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9926867054910268, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9926867054910268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2764]\tvalid_0's auc: 0.968034\n",
      "CPU times: user 8h 33min 45s, sys: 5min 2s, total: 8h 38min 48s\n",
      "Wall time: 1h 7min 46s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LGBMClassifier' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mtrain_pool_lgbm = data_train, target_train\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mval_pool_lgbm = data_val, target_val\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mbest_lgbm = train_model.random_search_cv_lgbm(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    train_pool_lgbm,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cat_features,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    lgbm_base_params,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    val_pool_lgbm,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    n_iter,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cv,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    refit=True,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    random_seed=RANDOM_STATE,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mbest_lgbm.save_model(ROOT / model_cfg[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bank-auc/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bank-auc/lib/python3.12/site-packages/IPython/core/magics/execution.py:1470\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bank-auc/lib/python3.12/site-packages/IPython/core/magics/execution.py:1439\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1437\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m expr_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1438\u001b[39m         code_2 = \u001b[38;5;28mself\u001b[39m.shell.compile(expr_val, source, \u001b[33m'\u001b[39m\u001b[33meval\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m         out = \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcode_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1441\u001b[39m     captured_exception = e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:15\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'LGBMClassifier' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_pool_lgbm = data_train, target_train\n",
    "val_pool_lgbm = data_val, target_val\n",
    "\n",
    "best_lgbm = train_model.random_search_cv_lgbm(\n",
    "    train_pool_lgbm,\n",
    "    cat_features,\n",
    "    lgbm_base_params,\n",
    "    val_pool_lgbm,\n",
    "    n_iter,\n",
    "    cv,\n",
    "    refit=True,\n",
    "    random_seed=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01227717-deea-4799-8550-29d7257d5e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x178314860>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iter = getattr(best_lgbm, \"best_iteration_\", None)  # int Ð¸Ð»Ð¸ None\n",
    "best_lgbm.booster_.save_model(ROOT / model_cfg[\"model_path\"], num_iteration=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c166731-0665-4bf7-8646-4421e4013ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params:  {'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.02, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 10000, 'n_jobs': -1, 'num_leaves': 106, 'objective': 'binary', 'random_state': 42, 'reg_alpha': 0.5214297905300546, 'reg_lambda': 1.236243687952708, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'metric': 'auc', 'min_data_in_leaf': 137, 'feature_fraction': 0.7282532043662948, 'bagging_fraction': 0.9926867054910268, 'bagging_freq': 2, 'max_cat_to_onehot': 6, 'cat_l2': 19.205212018125557, 'cat_smooth': 228.1355236625612}\n",
      "best iteration: 2764\n",
      "Best LGBM AUC: 0.9680\n"
     ]
    }
   ],
   "source": [
    "best_params_lgbm = best_lgbm.get_params()\n",
    "best_iter_lgbm = num_iter\n",
    "print(\"best_params: \", best_params_lgbm)\n",
    "print(f\"best iteration: {best_iter_lgbm}\")\n",
    "\n",
    "pred_best_lgbm = best_lgbm.predict_proba(data_val)[:, 1]\n",
    "auc = roc_auc_score(target_val, pred_best_lgbm)\n",
    "print(f\"Best LGBM AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b70c4a8-bb6c-4907-8487-daf56cecae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    \"library\": \"LightGBM\",\n",
    "    \"version\": lightgbm.__version__,\n",
    "    \"base_params\": lgbm_base_params,\n",
    "    \"best_search_params\": best_params_lgbm,\n",
    "    \"best_iteration\": best_iter_lgbm,\n",
    "    \"tree_count\": best_iter_lgbm + 1,\n",
    "    \"feature_order\": list(data_train.columns),\n",
    "    \"categorical_features\": list(cat_features),\n",
    "}\n",
    "\n",
    "io_utils.save_yaml(meta, ROOT / model_cfg[\"meta_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c81aa12a-0bbf-43b8-a99b-63665b79de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"auc_val\": float(auc)}\n",
    "preds_df = pd.DataFrame(\n",
    "    {\n",
    "        \"val_ids\": data_ids.loc[data_val.index, \"id\"],\n",
    "        \"val_preds\": pred_best_lgbm,\n",
    "        \"val_true\": target_val.squeeze(),\n",
    "    }\n",
    ")\n",
    "\n",
    "io_utils.save_df_parquet(preds_df, ROOT / model_cfg[\"preds_path\"])\n",
    "io_utils.save_yaml(metrics, ROOT / model_cfg[\"metrics_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dee85cf7-d2ff-4ab7-84fa-ef254598c985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>shap_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>log_duration</td>\n",
       "      <td>2.492747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.697729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>multiply_logs</td>\n",
       "      <td>0.338148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cos_month</td>\n",
       "      <td>0.330100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>credit_score</td>\n",
       "      <td>0.279030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sin_month</td>\n",
       "      <td>0.257648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>campaign_cat</td>\n",
       "      <td>0.223823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sin_day</td>\n",
       "      <td>0.204062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>log_balance</td>\n",
       "      <td>0.190997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job_education</td>\n",
       "      <td>0.169321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.163704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>job_marital</td>\n",
       "      <td>0.161722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>is_overdraft</td>\n",
       "      <td>0.112935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.103770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cos_day</td>\n",
       "      <td>0.097132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>education_marital</td>\n",
       "      <td>0.063460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pdays_cat</td>\n",
       "      <td>0.037038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.032915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>previous_cat</td>\n",
       "      <td>0.022850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>0.022810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>jb_mean</td>\n",
       "      <td>0.017316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job</td>\n",
       "      <td>0.014111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>was_contact</td>\n",
       "      <td>0.013966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  shap_value\n",
       "14       log_duration    2.492747\n",
       "4             contact    0.697729\n",
       "16      multiply_logs    0.338148\n",
       "19          cos_month    0.330100\n",
       "7        credit_score    0.279030\n",
       "18          sin_month    0.257648\n",
       "11       campaign_cat    0.223823\n",
       "20            sin_day    0.204062\n",
       "15        log_balance    0.190997\n",
       "9       job_education    0.169321\n",
       "0                 age    0.163704\n",
       "8         job_marital    0.161722\n",
       "17       is_overdraft    0.112935\n",
       "5            poutcome    0.103770\n",
       "21            cos_day    0.097132\n",
       "10  education_marital    0.063460\n",
       "12          pdays_cat    0.037038\n",
       "2             marital    0.032915\n",
       "13       previous_cat    0.022850\n",
       "3           education    0.022810\n",
       "22            jb_mean    0.017316\n",
       "1                 job    0.014111\n",
       "6         was_contact    0.013966"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values = visual.shap_values(best_lgbm, data_train)\n",
    "\n",
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b28a72-7ebb-4268-a9c4-8e29baf19e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bank-auc)",
   "language": "python",
   "name": "bank-auc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
